{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3136,"databundleVersionId":26502,"sourceType":"competition"}],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/entelpi/gridsearchcv-hyperparameter-tuning-titanic-compe?scriptVersionId=219746628\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"from sklearnex import patch_sklearn\npatch_sklearn()\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n\nfrom catboost import CatBoostClassifier\nimport lightgbm as lgb\nfrom sklearn.ensemble import AdaBoostClassifier, ExtraTreesClassifier, RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.linear_model import SGDClassifier, Ridge, LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report, ConfusionMatrixDisplay\nfrom sklearn.model_selection import GridSearchCV, KFold, cross_val_score\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom statistics import stdev\nfrom xgboost import XGBClassifier\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T08:52:04.129479Z","iopub.execute_input":"2025-01-29T08:52:04.129881Z","iopub.status.idle":"2025-01-29T08:52:06.575157Z","shell.execute_reply.started":"2025-01-29T08:52:04.129836Z","shell.execute_reply":"2025-01-29T08:52:06.573959Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"TRAIN_CSV = '/kaggle/input/titanic/train.csv'\nTEST_CSV = '/kaggle/input/titanic/test.csv'\n\ntrain_df = pd.read_csv(TRAIN_CSV)\ntest_df = pd.read_csv(TEST_CSV)\n\ntrain_df[\"Split_Part\"] = \"train\"\ntest_df[\"Split_Part\"] = \"test\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T08:52:06.576571Z","iopub.execute_input":"2025-01-29T08:52:06.577342Z","iopub.status.idle":"2025-01-29T08:52:06.595856Z","shell.execute_reply.started":"2025-01-29T08:52:06.577303Z","shell.execute_reply":"2025-01-29T08:52:06.594454Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Let's see what we have.","metadata":{}},{"cell_type":"code","source":"train_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T08:52:06.59801Z","iopub.execute_input":"2025-01-29T08:52:06.598337Z","iopub.status.idle":"2025-01-29T08:52:06.622994Z","shell.execute_reply.started":"2025-01-29T08:52:06.598307Z","shell.execute_reply":"2025-01-29T08:52:06.621752Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Let's see if we have missing values.","metadata":{}},{"cell_type":"code","source":"missing_fractions = train_df.isnull().mean().sort_values(ascending=False)\nmissing_fractions","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T08:52:06.624629Z","iopub.execute_input":"2025-01-29T08:52:06.62505Z","iopub.status.idle":"2025-01-29T08:52:06.635632Z","shell.execute_reply.started":"2025-01-29T08:52:06.625019Z","shell.execute_reply":"2025-01-29T08:52:06.634474Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Almost 20 % of age value is missing. I will use interpolation.","metadata":{}},{"cell_type":"code","source":"train_df[\"Age\"].interpolate(method = 'linear', limit_direction ='forward', inplace=True)\ntest_df[\"Age\"].interpolate(method = 'linear', limit_direction ='forward', inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T08:52:06.63711Z","iopub.execute_input":"2025-01-29T08:52:06.637545Z","iopub.status.idle":"2025-01-29T08:52:06.656938Z","shell.execute_reply.started":"2025-01-29T08:52:06.637501Z","shell.execute_reply":"2025-01-29T08:52:06.655544Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df = pd.concat((train_df, test_df))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T08:52:06.658314Z","iopub.execute_input":"2025-01-29T08:52:06.65869Z","iopub.status.idle":"2025-01-29T08:52:06.677Z","shell.execute_reply.started":"2025-01-29T08:52:06.658662Z","shell.execute_reply":"2025-01-29T08:52:06.675712Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"I will drop PassengerId, Ticket, and name columns (I think name does not related to survaving :D) also Ticket. Then I will use LabelEncoder to sex, cabin and Embarked.","metadata":{}},{"cell_type":"code","source":"df.drop([\"PassengerId\", \"Name\", \"Ticket\"], axis=1, inplace=True)\n\nlabel_encoder_sex = LabelEncoder() \nlabel_encoder_cabin = LabelEncoder() \nlabel_encoder_embarked = LabelEncoder() \n\ndf[\"Sex\"] = label_encoder_sex.fit_transform(df[\"Sex\"])\ndf[\"Cabin\"] = label_encoder_cabin.fit_transform(df[\"Cabin\"])\ndf[\"Embarked\"] = label_encoder_embarked.fit_transform(df[\"Embarked\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T08:52:06.678199Z","iopub.execute_input":"2025-01-29T08:52:06.678628Z","iopub.status.idle":"2025-01-29T08:52:06.705458Z","shell.execute_reply.started":"2025-01-29T08:52:06.678582Z","shell.execute_reply":"2025-01-29T08:52:06.704374Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Now, let's see the distributions of the outcomes.","metadata":{}},{"cell_type":"code","source":"train_df['Survived'].value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T08:52:06.708774Z","iopub.execute_input":"2025-01-29T08:52:06.709148Z","iopub.status.idle":"2025-01-29T08:52:06.733027Z","shell.execute_reply.started":"2025-01-29T08:52:06.709112Z","shell.execute_reply":"2025-01-29T08:52:06.731014Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Data Imbalance Check","metadata":{}},{"cell_type":"code","source":"train_df['Survived'].value_counts().plot.pie(figsize=(5, 5))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T08:52:06.734624Z","iopub.execute_input":"2025-01-29T08:52:06.735055Z","iopub.status.idle":"2025-01-29T08:52:06.868548Z","shell.execute_reply.started":"2025-01-29T08:52:06.735019Z","shell.execute_reply":"2025-01-29T08:52:06.867227Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_train = df[df['Split_Part']==\"train\"][\"Survived\"].values\nX_train = df[df['Split_Part']==\"train\"].drop([\"Survived\", \"Split_Part\"],axis=1)\n\ny_test = df[df['Split_Part']==\"test\"][\"Survived\"].values\nX_test = df[df['Split_Part']==\"test\"].drop([\"Survived\", \"Split_Part\"],axis=1)\n\nkf = KFold(n_splits=5, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T08:52:06.87013Z","iopub.execute_input":"2025-01-29T08:52:06.870453Z","iopub.status.idle":"2025-01-29T08:52:06.885535Z","shell.execute_reply.started":"2025-01-29T08:52:06.870422Z","shell.execute_reply":"2025-01-29T08:52:06.884532Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Makine öğrenmesi yöntemleri ve parametreleri belirleniyor\naccuracies = {}\nparameter_group = {}\nparameter_group[\"CatBoost\"] = {'function': CatBoostClassifier(random_seed=42, logging_level='Silent'),\n                               'parameters': {'iterations': [500],\n                                              'depth': [4, 5, 6],\n                                              'loss_function': ['Logloss', 'CrossEntropy'],\n                                              'l2_leaf_reg': np.logspace(-20, -19, 3),\n                                              'leaf_estimation_iterations': [10]\n                                              }}\nparameter_group[\"Decision Tree\"] = {'function': DecisionTreeClassifier(random_state=1),\n                                    'parameters': {'criterion': [\"entropy\", \"log_loss\"],\n                                                  'max_features': ['auto', 'sqrt', 'log2'],\n                                                  'ccp_alpha': [.001, .0001, .00001],\n                                                  'max_depth' : [5, 10, 15],}}\nparameter_group[\"Extra Trees\"] = {'function': ExtraTreesClassifier(),\n                                  'parameters': {'criterion': [\"gini\", \"entropy\", \"log_loss\"],\n                                                 'max_features': [\"sqrt\", \"log2\"]}}\nparameter_group[\"Gradient Boosting\"] = {'function': GradientBoostingClassifier(random_state=42),\n                                        'parameters': {\"learning_rate\": [0.01, 0.1],\n                                                        \"max_depth\":[3,8]\n                                                        }}\nparameter_group[\"K-Neightbors\"] = {'function': KNeighborsClassifier(),\n                                   'parameters': {'n_neighbors': [2, 5],\n                                                  'weights': [\"uniform\", \"distance\"],\n                                                  'algorithm': [\"ball_tree\", \"kd_tree\"],\n                                                  'metric': ['euclidean', 'manhattan'],\n                                                  'p': [1]}}\nparameter_group[\"LGBM\"] = {'function': lgb.LGBMClassifier(objective = 'multiclass', boosting_type = \"dart\", num_class= len(np.unique(y_train)), verbose = 0, random_state=42),\n                           'parameters': {'learning_rate': [0.01, .1],\n                                          'n_estimators': [8,16],\n                                          'reg_lambda' : [1,1.2]}}\nparameter_group[\"Logistic\"] = {'function': LogisticRegression(),\n                               'parameters': {\"penalty\":[\"l2\"]}}\nparameter_group[\"Random Forest\"] = {'function': RandomForestClassifier(),\n                                    'parameters': {'n_estimators': [5, 7, 10],\n                                                   'criterion': [\"gini\", \"entropy\", \"log_loss\"],\n                                                   'max_features': [\"sqrt\", \"log2\"]}}\nparameter_group[\"SVC\"] = {'function': SVC(),\n                          'parameters': {'C': [1, 10],\n                                         'kernel': [\"linear\", \"poly\", \"rbf\", \"sigmoid\"],\n                                         'degree': [5, 7, 10]}}\nparameter_group[\"XGB\"] = {'function': XGBClassifier(objective='multi:softmax', seed=42, num_class = len(np.unique(y_train)), max_depth=3),\n                          'parameters': {'min_child_weight': [1, 3],\n                                         'gamma': [0.5, 1],\n                                         'subsample': [0.6, 0.8],\n                                         'colsample_bytree': [0.6, 0.8]}}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T08:52:06.886757Z","iopub.execute_input":"2025-01-29T08:52:06.887173Z","iopub.status.idle":"2025-01-29T08:52:06.904992Z","shell.execute_reply.started":"2025-01-29T08:52:06.887121Z","shell.execute_reply":"2025-01-29T08:52:06.903525Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for method in parameter_group:\n    print(method)\n    classifier = parameter_group[method][\"function\"]\n    model = GridSearchCV(classifier, parameter_group[method][\"parameters\"], n_jobs=-1, verbose=1, cv=5)\n    model.fit(X_train, y_train)\n    print(model.best_params_)\n\n    y_predict = model.predict(X_train)\n    accuracy = accuracy_score(y_train, y_predict)\n    conf_matrix = confusion_matrix(y_train, y_predict)\n\n    print('TRAIN RESULTS')\n    print('Train Accuracy: {:.3f}'.format(accuracy))\n    print(classification_report(y_train, y_predict))\n    print('Confusion matrix:')\n    disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix)\n    disp.plot()\n    plt.show()\n\n    best_model = model.best_estimator_\n    \n    cross_val_accuracy = cross_val_score(best_model, X_train, y_train, cv=kf, scoring='accuracy')\n    mean_cv_accuracy = cross_val_accuracy.mean()\n    std_cv_accuracy = stdev(cross_val_accuracy)\n    \n    accuracies[method] = {'model':  model.best_estimator_,\n                          'Accuracy': accuracy,\n                          'Mean CV Accuracy': mean_cv_accuracy,\n                          'Std CV Accuracy': std_cv_accuracy\n                         }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T08:52:06.906419Z","iopub.execute_input":"2025-01-29T08:52:06.906848Z","iopub.status.idle":"2025-01-29T08:56:15.915685Z","shell.execute_reply.started":"2025-01-29T08:52:06.906813Z","shell.execute_reply":"2025-01-29T08:56:15.914732Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"accuracy_results = pd.DataFrame(accuracies).T\nprint(accuracy_results)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T08:56:15.91659Z","iopub.execute_input":"2025-01-29T08:56:15.917112Z","iopub.status.idle":"2025-01-29T08:56:16.015702Z","shell.execute_reply.started":"2025-01-29T08:56:15.917081Z","shell.execute_reply":"2025-01-29T08:56:16.014053Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Although K-Neighbors has the best Accuracy, its mean k-fold accuracy is low. Therefore I will use XGB.","metadata":{}},{"cell_type":"code","source":"y_pred = accuracies[\"XGB\"][\"model\"].predict(X_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T08:56:16.017163Z","iopub.execute_input":"2025-01-29T08:56:16.017578Z","iopub.status.idle":"2025-01-29T08:56:16.028642Z","shell.execute_reply.started":"2025-01-29T08:56:16.017535Z","shell.execute_reply":"2025-01-29T08:56:16.027766Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"submission_df = pd.concat([pd.read_csv(TEST_CSV)[\"PassengerId\"], pd.DataFrame(y_pred.astype(int), columns=[\"Survived\"])],axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T08:56:16.029978Z","iopub.execute_input":"2025-01-29T08:56:16.030373Z","iopub.status.idle":"2025-01-29T08:56:16.061554Z","shell.execute_reply.started":"2025-01-29T08:56:16.030342Z","shell.execute_reply":"2025-01-29T08:56:16.06038Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"submission_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T08:56:16.062967Z","iopub.execute_input":"2025-01-29T08:56:16.063428Z","iopub.status.idle":"2025-01-29T08:56:16.075611Z","shell.execute_reply.started":"2025-01-29T08:56:16.063381Z","shell.execute_reply":"2025-01-29T08:56:16.074336Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"submission_df.to_csv(\"submission.csv\", index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T08:56:16.076863Z","iopub.execute_input":"2025-01-29T08:56:16.077348Z","iopub.status.idle":"2025-01-29T08:56:16.101333Z","shell.execute_reply.started":"2025-01-29T08:56:16.077304Z","shell.execute_reply":"2025-01-29T08:56:16.09985Z"}},"outputs":[],"execution_count":null}]}
