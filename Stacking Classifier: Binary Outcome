{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3136,"databundleVersionId":26502,"sourceType":"competition"}],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/entelpi/stackingclassifier-titanic-competition?scriptVersionId=220029931\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"from sklearnex import patch_sklearn\npatch_sklearn()\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n\nfrom catboost import CatBoostClassifier\nimport lightgbm as lgb\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\nfrom sklearn.ensemble import AdaBoostClassifier, ExtraTreesClassifier, RandomForestClassifier, GradientBoostingClassifier, VotingClassifier, StackingClassifier\nfrom sklearn.linear_model import SGDClassifier, RidgeClassifier, LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report, ConfusionMatrixDisplay\nfrom sklearn.model_selection import GridSearchCV, KFold, cross_val_score\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom statistics import stdev\nfrom xgboost import XGBClassifier\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport logging\nlogging.disable(logging.INFO)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T06:07:43.085175Z","iopub.execute_input":"2025-01-31T06:07:43.085611Z","iopub.status.idle":"2025-01-31T06:07:45.471604Z","shell.execute_reply.started":"2025-01-31T06:07:43.085581Z","shell.execute_reply":"2025-01-31T06:07:45.470538Z"}},"outputs":[{"name":"stderr","text":"Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"TRAIN_CSV = '/kaggle/input/titanic/train.csv'\nTEST_CSV = '/kaggle/input/titanic/test.csv'\n\ntrain_df = pd.read_csv(TRAIN_CSV)\ntest_df = pd.read_csv(TEST_CSV)\n\ntrain_df[\"Split_Part\"] = \"train\"\ntest_df[\"Split_Part\"] = \"test\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T06:07:45.473139Z","iopub.execute_input":"2025-01-31T06:07:45.473381Z","iopub.status.idle":"2025-01-31T06:07:45.491923Z","shell.execute_reply.started":"2025-01-31T06:07:45.473356Z","shell.execute_reply":"2025-01-31T06:07:45.490728Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"Let's see what we have.","metadata":{}},{"cell_type":"code","source":"train_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T06:07:45.493734Z","iopub.execute_input":"2025-01-31T06:07:45.493962Z","iopub.status.idle":"2025-01-31T06:07:45.514836Z","shell.execute_reply.started":"2025-01-31T06:07:45.493924Z","shell.execute_reply":"2025-01-31T06:07:45.513792Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"   PassengerId  Survived  Pclass  \\\n0            1         0       3   \n1            2         1       1   \n2            3         1       3   \n3            4         1       1   \n4            5         0       3   \n\n                                                Name     Sex   Age  SibSp  \\\n0                            Braund, Mr. Owen Harris    male  22.0      1   \n1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n2                             Heikkinen, Miss. Laina  female  26.0      0   \n3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n4                           Allen, Mr. William Henry    male  35.0      0   \n\n   Parch            Ticket     Fare Cabin Embarked Split_Part  \n0      0         A/5 21171   7.2500   NaN        S      train  \n1      0          PC 17599  71.2833   C85        C      train  \n2      0  STON/O2. 3101282   7.9250   NaN        S      train  \n3      0            113803  53.1000  C123        S      train  \n4      0            373450   8.0500   NaN        S      train  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n      <th>Split_Part</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Braund, Mr. Owen Harris</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>A/5 21171</td>\n      <td>7.2500</td>\n      <td>NaN</td>\n      <td>S</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>PC 17599</td>\n      <td>71.2833</td>\n      <td>C85</td>\n      <td>C</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>Heikkinen, Miss. Laina</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>STON/O2. 3101282</td>\n      <td>7.9250</td>\n      <td>NaN</td>\n      <td>S</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n      <td>female</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113803</td>\n      <td>53.1000</td>\n      <td>C123</td>\n      <td>S</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Allen, Mr. William Henry</td>\n      <td>male</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>373450</td>\n      <td>8.0500</td>\n      <td>NaN</td>\n      <td>S</td>\n      <td>train</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":3},{"cell_type":"markdown","source":"Let's see if we have missing values.","metadata":{}},{"cell_type":"code","source":"missing_fractions = train_df.isnull().mean().sort_values(ascending=False)\nmissing_fractions","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T06:07:45.516537Z","iopub.execute_input":"2025-01-31T06:07:45.516778Z","iopub.status.idle":"2025-01-31T06:07:45.526851Z","shell.execute_reply.started":"2025-01-31T06:07:45.516751Z","shell.execute_reply":"2025-01-31T06:07:45.525812Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"Cabin          0.771044\nAge            0.198653\nEmbarked       0.002245\nPassengerId    0.000000\nSurvived       0.000000\nPclass         0.000000\nName           0.000000\nSex            0.000000\nSibSp          0.000000\nParch          0.000000\nTicket         0.000000\nFare           0.000000\nSplit_Part     0.000000\ndtype: float64"},"metadata":{}}],"execution_count":4},{"cell_type":"markdown","source":"I will use preprocess from https://www.kaggle.com/code/yunjun0914/titanic-randomforest-parameter-tuned","metadata":{}},{"cell_type":"code","source":"def preprocess(df):\n    df = df.copy()\n    def ticket_items(x):\n        items = x.split(\" \")\n        if len(items) == 1:\n            return \"None\"\n        return \" \".join(items[0:-1])\n    def ticket_num(x):\n        return x.split(\" \")[-1]\n\n    def cabin(x):\n        return \" \".join(x.split(\" \"))[0:1]\n    def item(x):\n        return \" \".join(v.replace(\".\", \"\").replace(\"/\", \"\") for v in x.split(\" \"))[0:3]\n\n    def num(x):\n        return \" \".join(v.replace(\"LINE\", \"0\") for v in x.split(\" \"))\n\n    def age(x):\n        if x < 10:\n            return \"0\"\n        elif x < 20:\n            return \"10\"\n        elif x < 30:\n            return \"20\"\n        elif x < 40:\n            return \"30\"\n        elif x < 50:\n            return \"40\"\n        elif x < 60:\n            return \"50\"\n        elif x < 70:\n            return \"60\"\n        elif x < 80:\n            return \"70\"\n        elif x < 90:\n            return \"80\"\n        elif x < 100:\n            return \"90\"\n        else:\n            return \"100\"\n\n\n    def normalize_name(x):\n        return \" \".join(v.strip(\"./\"'()[]'\"\") for v in x.split(\" \"))\n\n    def name(x):\n        if any (title in x for title in [\"Mrs\", \"Miss\", \"Ms\", \"Mme\", \"Mile\"]):\n            return \"Mrs/Miss\"\n\n        elif \"Mr\" in x:\n            return \"Mr\"\n        elif \"Master\" in x:\n            return \"Master\"\n        else:\n            return \"others\"\n\n    def len_name(x):\n        return len(\" \".join(x.split(\" \")))\n\n\n            \n    df[\"Ticket_items\"] = df[\"Ticket\"].apply(ticket_items)\n    df[\"Ticket_number\"] = df[\"Ticket\"].apply(ticket_num)\n    df[\"Sex\"] = df[\"Sex\"].map({\"male\": 0, \"female\": 1})\n    df[\"Cabin\"] = df[\"Cabin\"].fillna(\"None\")\n    df[\"Cabin\"] = df[\"Cabin\"].apply(cabin)\n    df[\"Ticket_items\"] = df[\"Ticket_items\"].apply(item)\n    df[\"Age\"] = df[\"Age\"].fillna(df[\"Age\"].median())\n    df[\"Ticket_number\"] = df[\"Ticket_number\"].apply(num)\n    df[\"Ticket_number\"] = df[\"Ticket_number\"].astype(int)\n    df[\"Age_categorical\"] = df[\"Age\"].apply(age)\n    df[\"Age_categorical\"] = df[\"Age_categorical\"].astype(int)\n    df[\"Family\"] = (df[\"SibSp\"] + df[\"Parch\"] + 1)\n    df[\"Len_Name\"] = df[\"Name\"].apply(len_name)\n    df[\"Name\"] = df[\"Name\"].apply(normalize_name)\n    df[\"Title\"] = df[\"Name\"].apply(name)\n    df[\"Fare\"] = df[\"Fare\"].fillna(df[\"Fare\"].median())\n    df[\"Categorical_Fare\"] = pd.qcut(df[\"Fare\"] / df[\"Family\"], 4, labels = [\"Low\", \"Mid\", \"High\", \"VeryHigh\"])\n    df[\"Categorical_Fare\"] = df[\"Categorical_Fare\"].map({\"Low\": 1, \"Mid\": 2, \"High\": 3, \"VeryHigh\": 4}).astype(int)\n    df = df.drop(\"Name\", axis = 1)\n    df = df.drop(\"Age\", axis = 1)\n    df = df.drop(\"Ticket\", axis = 1)\n\n    \n\n    cols = (\"Embarked\", \"Cabin\", \"Ticket_items\", \"Title\")\n    for c in cols:\n        lb = LabelEncoder()\n        lb.fit(df[c].values)\n        df[c] = lb.transform(list(df[c].values))\n        df[c] = df[c].astype(int)\n    \n    return df\n\ndf = preprocess(pd.concat((train_df, test_df)))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T06:07:45.527971Z","iopub.execute_input":"2025-01-31T06:07:45.528185Z","iopub.status.idle":"2025-01-31T06:07:45.582293Z","shell.execute_reply.started":"2025-01-31T06:07:45.528161Z","shell.execute_reply":"2025-01-31T06:07:45.581247Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T06:07:45.583486Z","iopub.execute_input":"2025-01-31T06:07:45.583703Z","iopub.status.idle":"2025-01-31T06:07:45.599303Z","shell.execute_reply.started":"2025-01-31T06:07:45.583677Z","shell.execute_reply":"2025-01-31T06:07:45.598261Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"   PassengerId  Survived  Pclass  Sex  SibSp  Parch     Fare  Cabin  Embarked  \\\n0            1       0.0       3    0      1      0   7.2500      7         2   \n1            2       1.0       1    1      1      0  71.2833      2         0   \n2            3       1.0       3    1      0      0   7.9250      7         2   \n3            4       1.0       1    1      1      0  53.1000      2         2   \n4            5       0.0       3    0      0      0   8.0500      7         2   \n\n  Split_Part  Ticket_items  Ticket_number  Age_categorical  Family  Len_Name  \\\n0      train             2          21171               20       2        23   \n1      train            14          17599               30       2        51   \n2      train            25        3101282               20       1        22   \n3      train            13         113803               30       2        44   \n4      train            13         373450               30       1        24   \n\n   Title  Categorical_Fare  \n0      1                 1  \n1      2                 4  \n2      2                 2  \n3      2                 4  \n4      1                 2  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Sex</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n      <th>Split_Part</th>\n      <th>Ticket_items</th>\n      <th>Ticket_number</th>\n      <th>Age_categorical</th>\n      <th>Family</th>\n      <th>Len_Name</th>\n      <th>Title</th>\n      <th>Categorical_Fare</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0.0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>7.2500</td>\n      <td>7</td>\n      <td>2</td>\n      <td>train</td>\n      <td>2</td>\n      <td>21171</td>\n      <td>20</td>\n      <td>2</td>\n      <td>23</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>71.2833</td>\n      <td>2</td>\n      <td>0</td>\n      <td>train</td>\n      <td>14</td>\n      <td>17599</td>\n      <td>30</td>\n      <td>2</td>\n      <td>51</td>\n      <td>2</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1.0</td>\n      <td>3</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7.9250</td>\n      <td>7</td>\n      <td>2</td>\n      <td>train</td>\n      <td>25</td>\n      <td>3101282</td>\n      <td>20</td>\n      <td>1</td>\n      <td>22</td>\n      <td>2</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>53.1000</td>\n      <td>2</td>\n      <td>2</td>\n      <td>train</td>\n      <td>13</td>\n      <td>113803</td>\n      <td>30</td>\n      <td>2</td>\n      <td>44</td>\n      <td>2</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0.0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8.0500</td>\n      <td>7</td>\n      <td>2</td>\n      <td>train</td>\n      <td>13</td>\n      <td>373450</td>\n      <td>30</td>\n      <td>1</td>\n      <td>24</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"y_train = df[df['Split_Part']==\"train\"][\"Survived\"].values\nX_train = df[df['Split_Part']==\"train\"].drop([\"Survived\", \"Split_Part\"],axis=1)\n\ny_test = df[df['Split_Part']==\"test\"][\"Survived\"].values\nX_test = df[df['Split_Part']==\"test\"].drop([\"Survived\", \"Split_Part\"],axis=1)\n\nkf = KFold(n_splits=5, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T06:07:45.600509Z","iopub.execute_input":"2025-01-31T06:07:45.600736Z","iopub.status.idle":"2025-01-31T06:07:45.62357Z","shell.execute_reply.started":"2025-01-31T06:07:45.600704Z","shell.execute_reply":"2025-01-31T06:07:45.622392Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# Makine öğrenmesi yöntemleri ve parametreleri belirleniyor\naccuracies = {}\nparameter_group = {}\nparameter_group[\"AdaBoost\"] = {'function': AdaBoostClassifier(random_state=42),\n                               'parameters': {'n_estimators': [10, 50, 100, 500],\n                                              'learning_rate': [0.0001, 0.001, 0.01, 0.1, 1.0]\n                                             }}\nparameter_group[\"CatBoost\"] = {'function': CatBoostClassifier(random_seed=42, logging_level='Silent'),\n                               'parameters': {'depth': [4, 5, 6],\n                                              'loss_function': ['Logloss', 'CrossEntropy'],\n                                              'l2_leaf_reg': np.logspace(-20, -19, 3)\n                                              }}\nparameter_group[\"Decision Tree\"] = {'function': DecisionTreeClassifier(random_state=1),\n                                    'parameters': {'criterion': [\"entropy\", \"log_loss\"],\n                                                  'max_features': ['auto', 'sqrt', 'log2'],\n                                                  'ccp_alpha': np.logspace(0.00001, 0.001, 5),\n                                                  'max_depth' : np.linspace(5, 50, 5)}}\nparameter_group[\"Extra Trees\"] = {'function': ExtraTreesClassifier(),\n                                  'parameters': {'criterion': [\"gini\", \"entropy\", \"log_loss\"],\n                                                 'max_features': [\"sqrt\", \"log2\"],\n                                                 'n_estimators': np.linspace(10,100,5)}}\nparameter_group[\"Gradient Boosting\"] = {'function': GradientBoostingClassifier(random_state=42),\n                                        'parameters': {\"learning_rate\": np.logspace(.00001,1,5),\n                                                        \"max_depth\":[3,8]\n                                                        }}\nparameter_group[\"K-Neightbors\"] = {'function': KNeighborsClassifier(),\n                                   'parameters': {'n_neighbors': [2, 5],\n                                                  'weights': [\"uniform\", \"distance\"],\n                                                  'algorithm': [\"ball_tree\", \"kd_tree\"],\n                                                  'metric': ['euclidean', 'manhattan'],\n                                                  'p': [1]}}\nparameter_group[\"LGBM\"] = {'function': lgb.LGBMClassifier(learning_rate = 0.00001, objective = 'binary', boosting_type = \"dart\", verbose = 0, random_state=42),\n                           'parameters': {'n_estimators': np.linspace(5,50,5),\n                                          'reg_lambda' : [1,1.2],\n                                          \"num_leaves\": [31, 63, 127],\n                                          \"max_depth\": [-1, 3, 5],\n                                          \"subsample\": [0.8, 1.0],\n                                          \"colsample_bytree\": [0.8, 1.0]}}\nparameter_group[\"Logistic\"] = {'function': LogisticRegression(),\n                               'parameters': {\"penalty\":[\"l2\"]}}\nparameter_group[\"Random Forest\"] = {'function': RandomForestClassifier(),\n                                    'parameters': {\"max_depth\" : np.linspace(5,30,6),\n                                                   \"criterion\" : [\"gini\", \"entropy\"], \n                                                   \"max_features\": np.linspace(2,10,5),\n                                                   \"min_samples_leaf\" : np.linspace(2,10,5),\n                                                   \"min_samples_split\" : np.linspace(2,10,5), \n                                                   \"n_estimators\": np.linspace(50, 500, 10)}}\nparameter_group[\"Ridge\"] = {'function': RidgeClassifier(),\n                            'parameters': {'solver': ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga', 'lbfgs']}}\nparameter_group[\"SGD\"] = {'function': SGDClassifier(random_state = 42),\n                          'parameters': {'loss': ['hinge', 'log_loss', 'modified_huber', 'squared_hinge', 'perceptron'],\n                                         'penalty': ['l2', 'l1', 'elasticnet']\n                                        }}\n#parameter_group[\"SVC\"] = {'function': SVC(),\n#                          'parameters': {'C': [1, 10],\n#                                         'kernel': [\"linear\", \"poly\", \"rbf\", \"sigmoid\"],\n#                                         'degree': [5, 7, 10]}}\nparameter_group[\"XGB\"] = {'function': XGBClassifier(objective='binary:logistic', seed=42),\n                          'parameters': {'min_child_weight': np.linspace(1,10,5),\n                                         'max_depth': [3, 5, 8,],\n                                         'learning_rate': [0.001, 0.1, 0.30],\n                                         'eta': np.logspace(0.01, 0.1, 5),\n                                         'reg_alpha': np.linspace(1, 50, 10),\n                                         'reg_lambda': np.linspace(5, 100, 10)}}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T06:08:10.485764Z","iopub.execute_input":"2025-01-31T06:08:10.486051Z","iopub.status.idle":"2025-01-31T06:08:10.50205Z","shell.execute_reply.started":"2025-01-31T06:08:10.486021Z","shell.execute_reply":"2025-01-31T06:08:10.500871Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"for method in parameter_group:\n    print(method)\n    try:\n        classifier = parameter_group[method][\"function\"]\n        model = GridSearchCV(classifier, parameter_group[method][\"parameters\"], n_jobs=-1, verbose=1, cv=5)\n        model.fit(X_train, y_train)\n        print(model.best_params_)\n    \n        y_predict = model.predict(X_train)\n        accuracy = accuracy_score(y_train, y_predict)\n        #conf_matrix = confusion_matrix(y_train, y_predict)\n    \n        print('TRAIN RESULTS')\n        print('Train Accuracy: {:.3f}'.format(accuracy))\n        print(classification_report(y_train, y_predict))\n    \n        best_model = model.best_estimator_\n        \n        cross_val_accuracy = cross_val_score(best_model, X_train, y_train, cv=kf, scoring='accuracy')\n        mean_cv_accuracy = cross_val_accuracy.mean()\n        std_cv_accuracy = stdev(cross_val_accuracy)\n        \n        accuracies[method] = {'model':  model.best_estimator_,\n                              'Accuracy': accuracy,\n                              'Mean CV Accuracy': mean_cv_accuracy,\n                              'Std CV Accuracy': std_cv_accuracy\n                             }\n    except:\n        print(\"Failed\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T06:07:45.856769Z","iopub.status.idle":"2025-01-31T06:07:45.857044Z","shell.execute_reply":"2025-01-31T06:07:45.856917Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"accuracy_results = pd.DataFrame(accuracies).T\nprint(accuracy_results)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T06:07:45.858016Z","iopub.status.idle":"2025-01-31T06:07:45.858289Z","shell.execute_reply":"2025-01-31T06:07:45.85815Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"accuracy_results = accuracy_results[accuracy_results[\"Mean CV Accuracy\"]>.7]\n\nvc = StackingClassifier(estimators=[(index, row[\"model\"]) for index, row in accuracy_results.iterrows()], final_estimator=LogisticRegression())\nvc.fit(X_train, y_train)\ny_pred = vc.predict(X_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T06:07:45.859153Z","iopub.status.idle":"2025-01-31T06:07:45.859482Z","shell.execute_reply":"2025-01-31T06:07:45.859349Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"submission_df = pd.concat([pd.read_csv(TEST_CSV)[\"PassengerId\"], pd.DataFrame(y_pred.astype(int), columns=[\"Survived\"])],axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T06:07:45.860391Z","iopub.status.idle":"2025-01-31T06:07:45.860634Z","shell.execute_reply":"2025-01-31T06:07:45.860516Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"submission_df.to_csv(\"submission.csv\", index=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T06:07:45.861328Z","iopub.status.idle":"2025-01-31T06:07:45.861562Z","shell.execute_reply":"2025-01-31T06:07:45.861447Z"}},"outputs":[],"execution_count":null}]}